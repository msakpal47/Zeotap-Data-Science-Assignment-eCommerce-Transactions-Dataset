{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccf50acf-2a97-43ae-9e8b-4ffee89b4638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "# Suppress specific warning\n",
    "warnings.filterwarnings('ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d680ae53-eb73-48e2-a9ab-46c91b5dce33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load datasets\n",
    "customers = pd.read_csv('Customers.csv')\n",
    "products = pd.read_csv('Products.csv')\n",
    "transactions = pd.read_csv('Transactions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66c4225e-9335-4633-8c0d-f21c9c1be0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge datasets\n",
    "data = transactions.merge(customers, on='CustomerID', how='inner').merge(products, on='ProductID', how='inner')\n",
    "\n",
    "# Ensure TransactionDate is parsed as datetime\n",
    "data['TransactionDate'] = pd.to_datetime(data['TransactionDate'], errors='coerce')\n",
    "\n",
    "# Compute the last transaction date for each customer\n",
    "last_transaction = data.groupby('CustomerID')['TransactionDate'].max().reset_index()\n",
    "last_transaction.columns = ['CustomerID', 'LastTransactionDate']\n",
    "\n",
    "# Compute Recency: Days since the last transaction\n",
    "current_date = pd.Timestamp.today()\n",
    "last_transaction['Recency'] = (current_date - last_transaction['LastTransactionDate']).dt.days\n",
    "\n",
    "# Aggregate other features\n",
    "customer_features = data.groupby('CustomerID').agg({\n",
    "    'TotalValue': ['sum', 'mean'],  # Total and average transaction value\n",
    "    'Quantity': 'sum',             # Total quantity purchased\n",
    "    'TransactionID': 'count',      # Number of transactions\n",
    "    'Category': lambda x: x.nunique()  # Number of unique product categories\n",
    "}).reset_index()\n",
    "\n",
    "# Rename columns\n",
    "customer_features.columns = ['CustomerID', 'TotalValue_sum', 'TotalValue_mean', \n",
    "                             'Quantity_sum', 'Transaction_count', 'Unique_categories']\n",
    "\n",
    "# Merge last transaction data with customer features\n",
    "customer_features = customer_features.merge(last_transaction, on='CustomerID', how='left')\n",
    "\n",
    "# One-hot encode product categories\n",
    "category_prefs = pd.get_dummies(data[['CustomerID', 'Category']], columns=['Category'], prefix='Category')\n",
    "category_prefs = category_prefs.groupby('CustomerID').sum().reset_index()\n",
    "\n",
    "# Combine aggregated features with category preferences\n",
    "final_features = customer_features.merge(category_prefs, on='CustomerID', how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3eb13e4-c349-419b-9119-fe4074c4c6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming 'final_features' is already defined, and contains customer data\n",
    "# final_features = ... (your dataset)\n",
    "\n",
    "# Drop non-numerical columns (like CustomerID, LastTransactionDate) for scaling\n",
    "numerical_features = final_features.drop(columns=['CustomerID', 'LastTransactionDate'])\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the numerical features and transform the data\n",
    "features_scaled = scaler.fit_transform(numerical_features)\n",
    "\n",
    "# Define the target variable (Total spend) and features\n",
    "X = features_scaled  # Features\n",
    "y = final_features['TotalValue_sum']  # Target variable (Total spend)\n",
    "\n",
    "# Split data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Now you can proceed with model training or any other operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cff6234-d686-4f94-916a-e5807063f178",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7615e2c5-8633-4fd9-8f1c-90a5349c5eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute similarity matrix (cosine similarity)\n",
    "similarity_matrix = cosine_similarity(features_scaled)\n",
    "\n",
    "# Create a DataFrame for similarity scores (similarity_df)\n",
    "similarity_df = pd.DataFrame(similarity_matrix, index=final_features['CustomerID'], columns=final_features['CustomerID'])\n",
    "\n",
    "# Function to get top 3 similar customers\n",
    "def get_top_similar_users(customer_id, similarity_df, top_n=3):\n",
    "    similar_customers = similarity_df[customer_id].sort_values(ascending=False).iloc[1:top_n+1]\n",
    "    return [(cust_id, score) for cust_id, score in similar_customers.items()]\n",
    "\n",
    "# Generate recommendations for customers C0001 to C0020\n",
    "customer_ids = [f'C{str(i).zfill(4)}' for i in range(1, 21)]\n",
    "recommendations = {}\n",
    "\n",
    "for cust_id in customer_ids:\n",
    "    if cust_id in similarity_df.index:\n",
    "        recommendations[cust_id] = get_top_similar_users(cust_id, similarity_df)\n",
    "\n",
    "# Convert recommendations to a DataFrame\n",
    "lookalike_data = []\n",
    "for customer, similar_list in recommendations.items():\n",
    "    for similar_customer, score in similar_list:\n",
    "        lookalike_data.append({'cust_id': customer, 'similar_cust': similar_customer, 'score': score})\n",
    "\n",
    "lookalike_df = pd.DataFrame(lookalike_data)\n",
    "\n",
    "# Save the recommendations to a CSV file\n",
    "lookalike_df.to_csv('Lookalike.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a347886e-ab6f-4147-8388-1a81e705f458",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a71aa63-fc83-4069-8936-e992b08813fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
